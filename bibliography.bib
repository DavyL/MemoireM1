@ARTICLE{coifortho,

  author={Coifman, R.R. and Wickerhauser, M.V.},

  journal={IEEE Transactions on Information Theory}, 

  title={Entropy-based algorithms for best basis selection}, 

  year={1992},

  volume={38},

  number={2},

  pages={713-718},

  doi={10.1109/18.119732}}

@article{IrregWav,
title = {Wavelets on irregular grids with arbitrary dilation matrices and frame atoms for L2(Rd)},
journal = {Applied and Computational Harmonic Analysis},
volume = {17},
number = {2},
pages = {119-140},
year = {2004},
note = {Special Issue: Frames in Harmonic Analysis, Part II},
issn = {1063-5203},
doi = {https://doi.org/10.1016/j.acha.2004.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S1063520304000442},
author = {Akram Aldroubi and Carlos Cabrelli and Ursula M. Molter},
keywords = {Frames, Irregular sampling, Wavelet sets, Wavelets},
abstract = {In this article, we develop a general method for constructing wavelets {|detAj|1/2ψ(Ajx−xj,k):j∈J,k∈K} on irregular lattices of the form X={xj,k∈Rd:j∈J,k∈K}, and with an arbitrary countable family of invertible d×d matrices {Aj∈GLd(R):j∈J} that do not necessarily have a group structure. This wavelet construction is a particular case of general atomic frame decompositions of L2(Rd) developed in this article, that allow other time frequency decompositions such as nonharmonic Gabor frames with nonuniform covering of the Euclidean space Rd. Possible applications include image and video compression, speech coding, image and digital data transmission, image analysis, estimations and detection, and seismology.}
}
@ARTICLE{mpmallat,

  author={Mallat, S.G. and Zhifeng Zhang},

  journal={IEEE Transactions on Signal Processing}, 

  title={Matching pursuits with time-frequency dictionaries}, 

  year={1993},

  volume={41},

  number={12},

  pages={3397-3415},

  doi={10.1109/78.258082}}

@article{basispursuit,
author = {Chen, Scott Shaobing and Donoho, David L. and Saunders, Michael A.},
title = {Atomic Decomposition by Basis Pursuit},
year = {2001},
issue_date = {2001},
publisher = {Society for Industrial and Applied Mathematics},
address = {USA},
volume = {43},
number = {1},
issn = {0036-1445},
url = {https://doi.org/10.1137/S003614450037906X},
doi = {10.1137/S003614450037906X},
abstract = {The time-frequency and time-scale communities have recently developed a large number of overcomplete waveform dictionaries---stationary wavelets, wavelet packets, cosine packets, chirplets, and warplets, to name a few. Decomposition into overcomplete systems is not unique, and several methods for decomposition have been proposed, including the method of frames (MOF), matching pursuit (MP), and, for special dictionaries, the best orthogonal basis (BOB). Basis pursuit (BP) is a principle for decomposing a signal into an "optimal"' superposition of dictionary elements, where optimal means having the smallest l1 norm of coefficients among all such decompositions. We give examples exhibiting several advantages over MOF, MP, and BOB, including better sparsity and superresolution. BP has interesting relations to ideas in areas as diverse as ill-posed problems, abstract harmonic analysis, total variation denoising, and multiscale edge denoising. BP in highly overcomplete dictionaries leads to large-scale optimization problems. With signals of length 8192 and a wavelet packet dictionary, one gets an equivalent linear program of size 8192 by 212,992. Such problems can be attacked successfully only because of recent advances in linear and quadratic programming by interior-point methods. We obtain reasonable success with a primal-dual logarithmic barrier method and conjugate-gradient solver.},
journal = {SIAM Rev.},
month = jan,
pages = {129–159},
numpages = {31},
keywords = {wavelet packets, interior-point methods for linear programming, wavelets, time-scale analysis, cosine packets, matching pursuit, overcomplete signal representation, total variation denoising, denoising, $ell^1$ norm optimization, time-frequency analysis, multiscale edges, MATLAB code}
}
@INPROCEEDINGS{ChenDonoho,

  author={Shaobing Chen and Donoho, D.},

  booktitle={Proceedings of 1994 28th Asilomar Conference on Signals, Systems and Computers}, 

  title={Basis pursuit}, 

  year={1994},

  volume={1},

  number={},

  pages={41-44 vol.1},

  doi={10.1109/ACSSC.1994.471413}}

@book{daubbook,
author = {Daubechies, Ingrid},
title = {Ten Lectures on Wavelets},
publisher = {Society for Industrial and Applied Mathematics},
year = {1992},
doi = {10.1137/1.9781611970104},
address = {},
edition   = {},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611970104},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611970104}
}
@ARTICLE{feuer,
    author = {Arie Feuer and Senior Member and Arkadi Nemirovski},
    title = {On sparse representations in pairs of bases},
    journal = {IEEE Trans. Inf. Theory},
    year = {2003},
    pages = {1579--1581}
}
@ARTICLE{eladBruckstein,

  author={Elad, M. and Bruckstein, A.M.},

  journal={IEEE Transactions on Information Theory}, 

  title={A generalized uncertainty principle and sparse representation in pairs of bases}, 

  year={2002},

  volume={48},

  number={9},

  pages={2558-2567},

  doi={10.1109/TIT.2002.801410}}
@article{donohostark,
 ISSN = {00361399},
 URL = {http://www.jstor.org/stable/2101993},
 abstract = {The uncertainty principle can easily be generalized to cases where the "sets of concentration" are not intervals. Such generalizations are presented for continuous and discrete-time functions, and for several measures of "concentration" (e.g., L2 and L1 measures). The generalizations explain interesting phenomena in signal recovery problems where there is an interplay of missing data, sparsity, and bandlimiting.},
 author = {David L. Donoho and Philip B. Stark},
 journal = {SIAM Journal on Applied Mathematics},
 number = {3},
 pages = {906--931},
 publisher = {Society for Industrial and Applied Mathematics},
 title = {Uncertainty Principles and Signal Recovery},
 volume = {49},
 year = {1989}
}
@book{foucartbook,
author = {Foucart, Simon and Rauhut, Holger},
title = {A Mathematical Introduction to Compressive Sensing},
year = {2013},
isbn = {0817649476},
publisher = {Birkh\"{a}user Basel},
abstract = {At the intersection of mathematics, engineering, and computer science sits the thriving field of compressive sensing. Based on the premise that data acquisition and compression can be performed simultaneously, compressive sensing finds applications in imaging, signal processing, and many other domains. In the areas of applied mathematics, electrical engineering, and theoretical computer science, an explosion of research activity has already followed the theoretical results that highlighted the efficiency of the basic principles. The elegant ideas behind these principles are also of independent interest to pure mathematicians.A Mathematical Introduction to Compressive Sensing gives a detailed account of the core theory upon which the field is build. With only moderate prerequisites, it is an excellent textbook for graduate courses in mathematics, engineering, and computer science. It also serves as a reliable resource for practitioners and researchers in these disciplines who want to acquire a careful understanding of the subject. A Mathematical Introduction to Compressive Sensing uses a mathematical perspective to present the core of the theory underlying compressive sensing.}
}
@article{CR,
	IDS={CandesSparsityIncoherence},
   title={Sparsity and incoherence in compressive sampling},
   volume={23},
   ISSN={1361-6420},
   url={http://dx.doi.org/10.1088/0266-5611/23/3/008},
   DOI={10.1088/0266-5611/23/3/008},
   number={3},
   journal={Inverse Problems},
   publisher={IOP Publishing},
   author={Candès, Emmanuel and Romberg, Justin},
   year={2007},
   month={Apr},
   pages={969–985}
}

@ARTICLE{CT,
	IDS={CandesTaoUniv},
  author={Candes, Emmanuel J. and Tao, Terence},

  journal={IEEE Transactions on Information Theory}, 

  title={Near-Optimal Signal Recovery From Random Projections: Universal Encoding Strategies?}, 

  year={2006},

  volume={52},

  number={12},

  pages={5406-5425},

  doi={10.1109/TIT.2006.885507}}

@article{CRT,
author = {Candes, E. J. and Romberg, J. and Tao, T.},
title = {Robust Uncertainty Principles: Exact Signal Reconstruction from Highly Incomplete Frequency Information},
year = {2006},
issue_date = {February 2006},
publisher = {IEEE Press},
volume = {52},
number = {2},
issn = {0018-9448},
url = {https://doi.org/10.1109/TIT.2005.862083},
doi = {10.1109/TIT.2005.862083},
abstract = {This paper considers the model problem of reconstructing an object from incomplete frequency samples. Consider a discrete-time signal f∈CN and a randomly chosen set of frequencies Ω. Is it possible to reconstruct f from the partial knowledge of its Fourier coefficients on the set Ω? A typical result of this paper is as follows. Suppose that f is a superposition of |T| spikes f(t)=στ∈Tf(τ)δ(t-τ) obeying |T|≤CM·(log N)-1 · |Ω| for some constant CM>0. We do not know the locations of the spikes nor their amplitudes. Then with probability at least 1-O(N-M), f can be reconstructed exactly as the solution to the ℓ1 minimization problem. In short, exact recovery may be obtained by solving a convex optimization problem. We give numerical values for CM which depend on the desired probability of success. Our result may be interpreted as a novel kind of nonlinear sampling theorem. In effect, it says that any signal made out of |T| spikes may be recovered by convex programming from almost every set of frequencies of size O(|T|·logN). Moreover, this is nearly optimal in the sense that any method succeeding with probability 1-O(N-M) would in general require a number of frequency samples at least proportional to |T|·logN. The methodology extends to a variety of other situations and higher dimensions. For example, we show how one can reconstruct a piecewise constant (one- or two-dimensional) object from incomplete frequency samples - provided that the number of jumps (discontinuities) obeys the condition above - by minimizing other convex functionals such as the total variation of f.},
journal = {IEEE Trans. Inf. Theor.},
month = feb,
pages = {489–509},
numpages = {21},
keywords = {Convex optimization, trigonometric expansions, total-variation minimization, sparsity, free probability, random matrices, duality in optimization, linear programming, uncertainty principle, image reconstruction}
}

  


@ARTICLE{taoprime,
       author = {{Tao}, Terence},
        title = "{An uncertainty principle for cyclic groups of prime order}",
      journal = {arXiv Mathematics e-prints},
     keywords = {Mathematics - Classical Analysis and ODEs, Mathematics - Number Theory, 42A99},
         year = 2003,
        month = aug,
          eid = {math/0308286},
        pages = {math/0308286},
archivePrefix = {arXiv},
       eprint = {math/0308286},
 primaryClass = {math.CA},
       adsurl = {https://ui.adsabs.harvard.edu/abs/2003math......8286T},
      adsnote = {Provided by the SAO/NASA Astrophysics Data System}
}

@article{DonohoHuo,
author = {Donoho, D. L. and Huo, X.},
title = {Uncertainty Principles and Ideal Atomic Decomposition},
year = {2006},
issue_date = {November 2001},
publisher = {IEEE Press},
volume = {47},
number = {7},
issn = {0018-9448},
url = {https://doi.org/10.1109/18.959265},
doi = {10.1109/18.959265},
abstract = {Suppose a discrete-time signal S(t), 0⩽t<N, is a superposition of atoms taken from a combined time-frequency dictionary made of spike sequences 1{t=τ} and sinusoids exp{2πiwt/N}/√N. Can one recover, from knowledge of S alone, the precise collection of atoms going to make up S? Because every discrete-time signal can be represented as a superposition of spikes alone, or as a superposition of sinusoids alone, there is no unique way of writing S as a sum of spikes and sinusoids in general. We prove that if S is representable as a highly sparse superposition of atoms from this time-frequency dictionary, then there is only one such highly sparse representation of S, and it can be obtained by solving the convex optimization problem of minimizing the l1 norm of the coefficients among all decompositions. Here “highly sparse” means that Nt+Nw<√N/2 where Nt is the number of time atoms, Nw is the number of frequency atoms, and N is the length of the discrete-time signal. Underlying this result is a general l1 uncertainty principle which says that if two bases are mutually incoherent, no nonzero signal can have a sparse representation in both bases simultaneously. For the above setting, the bases are sinusoids and spikes, and mutual incoherence is measured in terms of the largest inner product between different basis elements. The uncertainty principle holds for a variety of interesting basis pairs, not just sinusoids and spikes. The results have idealized applications to band-limited approximation with gross errors, to error-correcting encryption, and to separation of uncoordinated sources. Related phenomena hold for functions of a real variable, with basis pairs such as sinusoids and wavelets, and for functions of two variables, with basis pairs such as wavelets and ridgelets. In these settings, if a function f is representable by a sufficiently sparse superposition of terms taken from both bases, then there is only one such sparse representation; it may be obtained by minimum l1 norm atomic decomposition. The condition “sufficiently sparse” becomes a multiscale condition; for example, that the number of wavelets at level j plus the number of sinusoids in the jth dyadic frequency band are together less than a constant times 2j/2 },
journal = {IEEE Trans. Inf. Theor.},
month = sep,
pages = {2845–2862},
numpages = {18}
}

  


@book{mallatbook,
author = {Mallat, Stphane},
title = {A Wavelet Tour of Signal Processing, Third Edition: The Sparse Way},
year = {2008},
isbn = {0123743702},
publisher = {Academic Press, Inc.},
address = {USA},
edition = {3rd},
abstract = {Mallat's book is the undisputed reference in this field - it is the only one that covers the essential material in such breadth and depth. - Laurent Demanet, Stanford UniversityThe new edition of this classic book gives all the major concepts, techniques and applications of sparse representation, reflecting the key role the subject plays in today's signal processing. The book clearly presents the standard representations with Fourier, wavelet and time-frequency transforms, and the construction of orthogonal bases with fast algorithms. The central concept of sparsity is explained and applied to signal compression, noise reduction, and inverse problems, while coverage is given to sparse representations in redundant dictionaries, super-resolution and compressive sensing applications.Features:* Balances presentation of the mathematics with applications to signal processing* Algorithms and numerical examples are implemented in WaveLab, a MATLAB toolbox* Companion website for instructors and selected solutions and code available for studentsNew in this edition* Sparse signal representations in dictionaries* Compressive sensing, super-resolution and source separation* Geometric image processing with curvelets and bandlets* Wavelets for computer graphics with lifting on surfaces* Time-frequency audio processing and denoising* Image compression with JPEG-2000* New and updated exercisesA Wavelet Tour of Signal Processing: The Sparse Way, third edition, is an invaluable resource for researchers and R&D engineers wishing to apply the theory in fields such as image processing, video processing and compression, bio-sensing, medical imaging, machine vision and communications engineering.Stephane Mallat is Professor in Applied Mathematics at cole Polytechnique, Paris, France. From 1986 to 1996 he was a Professor at the Courant Institute of Mathematical Sciences at New York University, and between 2001 and 2007, he co-founded and became CEO of an image processing semiconductor company.Companion website: A Numerical Tour of Signal Processing Includes all the latest developments since the book was published in 1999, including itsapplication to JPEG 2000 and MPEG-4Algorithms and numerical examples are implemented in Wavelab, a MATLAB toolboxBalances presentation of the mathematics with applications to signal processing}
}

  


@ARTICLE{daubpers,

  author={Daubechies, I.},

  journal={Proceedings of the IEEE}, 

  title={Where do wavelets come from? A personal point of view}, 

  year={1996},

  volume={84},

  number={4},

  pages={510-513},

  doi={10.1109/5.488696}}

@book{meyer, 
place={Cambridge}, 
series={Cambridge Studies in Advanced Mathematics}, 
title={Wavelets and Operators}, 
volume={1}, DOI={10.1017/CBO9780511623820}, publisher={Cambridge University Press}, author={Meyer, Yves}, editor={Salinger, D. H.Translator}, year={1993}, collection={Cambridge Studies in Advanced Mathematics}}

@article{haar,
  TITLE = {{Zur Theorie der orthogonalen Funktionensysteme}},
  AUTHOR = {Haar, Alfred},
  URL = {https://hal.archives-ouvertes.fr/hal-01333722},
  JOURNAL = {{Mathematische Annalen}},
  PUBLISHER = {{Springer Verlag}},
  VOLUME = {69},
  NUMBER = {3},
  PAGES = {331-371},
  YEAR = {1910},
  DOI = {10.1007/BF01456326},
  HAL_ID = {hal-01333722},
  HAL_VERSION = {v1},
}

@book{groth,
publisher = {American Mathematical Society},
series = {Memoirs of the American Mathematical Society},
author = {Grothendieck Alexandre},
address = {Providence},
booktitle = {Produits tensoriels topologiques et espaces nucléaires / A. Grothendieck},
isbn = {0-8218-1216-5},
title = {Produits tensoriels topologiques et espaces nucléaires  / A. Grothendieck},
keywords = {Algèbre linéaire},
language = {fre},
year = {1955},
}

@ARTICLE{traceclass,

  author = {Richman, Fred and Bridges, Douglas and Schuster, Peter},

  title = {Trace-class operators},

  journal = {Houston Journal of Mathematics},

  year = {2002},

  volume = {28},

  pages = {565--583},

  number = {3},

  file = {RBS02.pdf:RBS02.pdf:PDF;RBS02.pdf:files\\RBS02.pdf:PDF},

  keywords = {bib,con}

}
@book{acQuef,
publisher = {Calvage et Mounet},
series = {Mathématiques en devenir},
title = {Analyse complexe et applications  : cours et exercices / Hervé Queffélec, Martine Queffélec},
year = {DL 2019},
booktitle = {Analyse complexe et applications : cours et exercices / Hervé Queffélec, Martine Queffélec},
isbn = {978-2-916352-59-6},
keywords = {Analyse mathématique},
language = {fre},
author = {Queffélec, Hervé et Queffélec, Martine},
address = {Paris},
}
@article{jaffardondelettes,
	URL = {https://perso.math.u-pem.fr/jaffard.stephane/pdf/decompositions_en_ondelettes.pdf},
	author={S.Jaffard},
	title={Décompositions en ondelettes},
}

@article{jaffard,
 ISSN = {02141493, 20144350},
 URL = {http://www.jstor.org/stable/43736311},
 author = {S. Jaffard},
 journal = {Publicacions Matemàtiques},
 number = {1},
 pages = {155--168},
 publisher = {Universitat Autònoma de Barcelona},
 title = {POINTWISE SMOOTHNESS, TWO-MICROLOCALIZATION AND WAVELET COEFFICIENTS},
 volume = {35},
 year = {1991}
}

@unpublished{surlestraces,
  TITLE = {{Sur les traces d'op{\'e}rateurs (De Grothendieck {\`a} Lidskii)}},
  AUTHOR = {Robert, Didier},
  URL = {https://hal.archives-ouvertes.fr/hal-01015295},
  NOTE = {working paper or preprint},
  YEAR = {2014},
  MONTH = Apr,
  PDF = {https://hal.archives-ouvertes.fr/hal-01015295/file/trace_gazette_V2.pdf},
  HAL_ID = {hal-01015295},
  HAL_VERSION = {v1},
}

@incollection{mallatframe,
title = {CHAPTER 5 - Frames},
editor = {Mallat Stéphane},
booktitle = {A Wavelet Tour of Signal Processing (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Boston},
pages = {155-204},
year = {2009},
isbn = {978-0-12-374370-1},
doi = {https://doi.org/10.1016/B978-0-12-374370-1.00009-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780123743701000094},
author = {Mallat Stéphane}
}
@inbook{daubch3,
author={Daubechies, Ingrid},
title = {3. Discrete Wavelet Transforms: Frames},
booktitle = {Ten Lectures on Wavelets},
chapter = {},
pages = {53-105},
doi = {10.1137/1.9781611970104.ch3},
URL = {https://epubs.siam.org/doi/abs/10.1137/1.9781611970104.ch3},
eprint = {https://epubs.siam.org/doi/pdf/10.1137/1.9781611970104.ch3}
}
@ARTICLE{LustigCS,

  author={Lustig, Michael and Donoho, David L. and Santos, Juan M. and Pauly, John M.},

  journal={IEEE Signal Processing Magazine}, 

  title={Compressed Sensing MRI}, 

  year={2008},

  volume={25},

  number={2},

  pages={72-82},

  doi={10.1109/MSP.2007.914728}}


@article{ViewsSparseRadon,
    author = {Trad, Daniel and Ulrych, Tadeusz and Sacchi, Mauricio},
    title = "{Latest views of the sparse Radon transform}",
    journal = {Geophysics},
    volume = {68},
    number = {1},
    pages = {386-399},
    year = {2003},
    month = {01},
    abstract = "{The Radon transform (RT) suffers from the typical problems of loss of resolution and aliasing that arise as a consequence of incomplete information, including limited aperture and discretization. Sparseness in the Radon domain is a valid and useful criterion for supplying this missing information, equivalent somehow to assuming smooth amplitude variation in the transition between known and unknown (missing) data. Applying this constraint while honoring the data can become a serious challenge for routine seismic processing because of the very limited processing time available, in general, per common midpoint. To develop methods that are robust, easy to use and flexible to adapt to different problems we have to pay attention to a variety of algorithms, operator design, and estimation of the hyperparameters that are responsible for the regularization of the solution.In this paper, we discuss fast implementations for several varieties of RT in the time and frequency domains. An iterative conjugate gradient algorithm with fast Fourier transform multiplication is used in all cases. To preserve the important property of iterative subspace methods of regularizing the solution by the number of iterations, the model weights are incorporated into the operators. This turns out to be of particular importance, and it can be understood in terms of the singular vectors of the weighted transform. The iterative algorithm is stopped according to a general cross validation criterion for subspaces. We apply this idea to several known implementations and compare results in order to better understand differences between, and merits of, these algorithms.}",
    issn = {0016-8033},
    doi = {10.1190/1.1543224},
    url = {https://doi.org/10.1190/1.1543224},
    eprint = {https://pubs.geoscienceworld.org/geophysics/article-pdf/68/1/386/3203946/gsgpy\_68\_1\_386.pdf},
}



@ARTICLE{RobustSparseRadon,

  author={Wang, Benfeng and Zhang, Yingqiang and Lu, Wenkai and Geng, Jianhua},

  journal={IEEE Transactions on Geoscience and Remote Sensing}, 

  title={A Robust and Efficient Sparse Time-Invariant Radon Transform in the Mixed Time–Frequency Domain}, 

  year={2019},

  volume={57},

  number={10},

  pages={7558-7566},

  doi={10.1109/TGRS.2019.2914086}}

@misc{XraySparse,
      title={Sparse-View X-Ray CT Reconstruction Using $\ell_1$ Prior with Learned Transform}, 
      author={Xuehang Zheng and Il Yong Chun and Zhipeng Li and Yong Long and Jeffrey A. Fessler},
      year={2019},
      eprint={1711.00905},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}
@article{CSTom,
author = {Choi, Kihwan and Wang, Jing and Zhu, Lei and Suh, Tae-Suk and Boyd, Stephen and Xing, Lei},
title = {Compressed sensing based cone-beam computed tomography reconstruction with a first-order methoda)},
journal = {Medical Physics},
volume = {37},
number = {9},
pages = {5113-5125},
keywords = {Computed tomography, Reconstruction, Numerical optimization, General statistical methods, computerised tomography, dosimetry, image reconstruction, iterative methods, least squares approximations, medical image processing, minimisation, phantoms, cone-beam computed tomography, compressed sensing, weighted least-squares, Nesterov's first order method, Cone beam computed tomography, Medical imaging, Medical image reconstruction, Medical image noise, Image reconstruction, Computed tomography, Dosimetry, Medical X-ray imaging, Photons, Medical image quality},
doi = {https://doi.org/10.1118/1.3481510},
url = {https://aapm.onlinelibrary.wiley.com/doi/abs/10.1118/1.3481510},
eprint = {https://aapm.onlinelibrary.wiley.com/doi/pdf/10.1118/1.3481510},
abstract = {Purpose: This article considers the problem of reconstructing cone-beam computed tomography (CBCT) images from a set of undersampled and potentially noisy projection measurements. Methods: The authors cast the reconstruction as a compressed sensing problem based on norm minimization constrained by statistically weighted least-squares of CBCT projection data. For accurate modeling, the noise characteristics of the CBCT projection data are used to determine the relative importance of each projection measurement. To solve the compressed sensing problem, the authors employ a method minimizing total-variation norm, satisfying a prespecified level of measurement consistency using a first-order method developed by Nesterov. Results: The method converges fast to the optimal solution without excessive memory requirement, thanks to the method of iterative forward and back-projections. The performance of the proposed algorithm is demonstrated through a series of digital and experimental phantom studies. It is found a that high quality CBCT image can be reconstructed from undersampled and potentially noisy projection data by using the proposed method. Both sparse sampling and decreasing x-ray tube current (i.e., noisy projection data) lead to the reduction of radiation dose in CBCT imaging. Conclusions: It is demonstrated that compressed sensing outperforms the traditional algorithm when dealing with sparse, and potentially noisy, CBCT projection views.},
year = {2010}
}

@article{TomoInv,
    author = {Loris, Ignace and Nolet, Guust and Daubechies, Ingrid and Dahlen, F. A.},
    title = "{Tomographic inversion using ℓ1-norm regularization of wavelet coefficients}",
    journal = {Geophysical Journal International},
    volume = {170},
    number = {1},
    pages = {359-370},
    year = {2007},
    month = {07},
    abstract = "{We propose the use of ℓ1 regularization in a wavelet basis for the solution of linearized seismic tomography problems A m = d, allowing for the possibility of sharp discontinuities superimposed on a smoothly varying background. An iterative method is used to find a sparse solution m that contains no more fine-scale structure than is necessary to fit the data d to within its assigned errors.}",
    issn = {0956-540X},
    doi = {10.1111/j.1365-246X.2007.03409.x},
    url = {https://doi.org/10.1111/j.1365-246X.2007.03409.x},
    eprint = {https://academic.oup.com/gji/article-pdf/170/1/359/5924549/170-1-359.pdf},
}



@article{DonohoForMost,
author = {Donoho, David L.},
title = {For most large underdetermined systems of linear equations the minimal 𝓁1-norm solution is also the sparsest solution},
journal = {Communications on Pure and Applied Mathematics},
volume = {59},
number = {6},
pages = {797-829},
doi = {https://doi.org/10.1002/cpa.20132},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/cpa.20132},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/cpa.20132},
abstract = {Abstract We consider linear equations y = Φx where y is a given vector in ℝn and Φ is a given n × m matrix with n < m ≤ τn, and we wish to solve for x ∈ ℝm. We suppose that the columns of Φ are normalized to the unit 𝓁2-norm, and we place uniform measure on such Φ. We prove the existence of ρ = ρ(τ) > 0 so that for large n and for all Φ's except a negligible fraction, the following property holds: For every y having a representation y = Φx0 by a coefficient vector x0 ∈ ℝm with fewer than ρ · n nonzeros, the solution x1 of the 𝓁1-minimization problem \$\${\rm min} \|x\|\_{1} \;\;{subject \; to}\;\; \Phi x = y\$\$ is unique and equal to x0. In contrast, heuristic attempts to sparsely solve such systems—greedy algorithms and thresholding—perform poorly in this challenging setting. The techniques include the use of random proportional embeddings and almost-spherical sections in Banach space theory, and deviation bounds for the eigenvalues of random Wishart matrices. © 2006 Wiley Periodicals, Inc.},
year = {2006}
}

@ARTICLE{DonohoCS,

  author={Donoho, D.L.},

  journal={IEEE Transactions on Information Theory}, 

  title={Compressed sensing}, 

  year={2006},

  volume={52},

  number={4},

  pages={1289-1306},

  doi={10.1109/TIT.2006.871582}}

@ARTICLE{NPHard,

  author={Tillmann, Andreas M.},

  journal={IEEE Signal Processing Letters}, 

  title={On the Computational Intractability of Exact and Approximate Dictionary Learning}, 

  year={2015},

  volume={22},

  number={1},

  pages={45-49},

  doi={10.1109/LSP.2014.2345761}}

@article{WattsStrogatz98,
     	address = {Department of Theoretical and Applied Mechanics, Cornell University, Ithaca, New York 14853, USA. djw24@columbia.edu},
 	author = {Watts, Duncan J. and Strogatz, Steven H.},
 	citeulike-linkout-0 = {http://dx.doi.org/10.1038/30918},
 	doi = {10.1038/30918},
  	issn = {0028-0836},
 	journal = {Nature},
   	keywords = {classic networks},
   	month = jun,
    	number = 6684,
 	pages = {440--442},
	publisher = {Nature Publishing Group},
	timestamp = {2018-12-02T16:09:07.000+0100},
     	title = {Collective dynamics of 'small-world' networks},
      	url = {http://dx.doi.org/10.1038/30918},
 	volume = 393,
	year = 1998
}


